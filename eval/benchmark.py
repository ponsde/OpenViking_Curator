#!/usr/bin/env python3
"""
Curator Eval Benchmark â€” å¯¹æ¯”è£¸ OpenViking æ£€ç´¢ vs Curator å…¨æµç¨‹ã€‚

å…¬å¹³å¯¹æ¯”ï¼šä¸¤è¾¹éƒ½æ¯”æ£€ç´¢å†…å®¹çš„å…³é”®è¯å‘½ä¸­ç‡ã€‚
- raw OVï¼šæ£€ç´¢ç»“æœçš„ L2 content
- Curatorï¼šæ£€ç´¢ç»“æœçš„ context_textï¼ˆä¸æ˜¯ LLM ç”Ÿæˆçš„ answerï¼‰

ç”¨æ³•:
  cd /home/ponsde/OpenViking_test && source .venv/bin/activate
  python3 /home/ponsde/OpenViking_Curator/eval/benchmark.py

è¾“å‡º: eval/results/benchmark_YYYY-MM-DD.json + ç»ˆç«¯è¡¨æ ¼
"""

import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path

# â”€â”€ Setup â”€â”€
sys.path.insert(0, '/home/ponsde/OpenViking_Curator')

# åŠ è½½ .env
from pathlib import Path as _Path
_env_file = _Path('/home/ponsde/OpenViking_Curator/.env')
if _env_file.exists():
    for line in _env_file.read_text().splitlines():
        line = line.strip()
        if line and not line.startswith('#') and '=' in line:
            k, v = line.split('=', 1)
            os.environ.setdefault(k.strip(), v.strip())

os.environ.setdefault('OPENVIKING_CONFIG_FILE', '/home/ponsde/OpenViking_test/ov.conf')
os.environ.setdefault('CURATOR_DATA_PATH', '/home/ponsde/OpenViking_test/data')

# â”€â”€ 10 ä¸ªå›ºå®šæµ‹è¯• Query â”€â”€
BENCHMARK_QUERIES = [
    {
        "id": 1,
        "query": "grok2api æ€ä¹ˆéƒ¨ç½²å’Œé…ç½®",
        "expected_topics": ["grok2api", "ç«¯å£", "8000", "API", "ä»£ç†"],
        "category": "éƒ¨ç½²ç»éªŒ",
    },
    {
        "id": 2,
        "query": "OpenViking search å’Œ find ç»“æœä¸ä¸€è‡´æ€ä¹ˆåŠ",
        "expected_topics": ["éç¡®å®šæ€§", "Jaccard", "å‘é‡æ£€ç´¢", "æœ¬åœ°ç´¢å¼•", "ç¼“è§£"],
        "category": "è¸©å‘ç»éªŒ",
    },
    {
        "id": 3,
        "query": "Curator è·¯ç”±æ€ä¹ˆä»æ­£åˆ™å‡çº§åˆ° LLM",
        "expected_topics": ["LLM", "æ„å›¾", "ç¡¬æ‹¦æˆª", "Grok", "è§„åˆ™"],
        "category": "æ¶æ„å†³ç­–",
    },
    {
        "id": 4,
        "query": "SSE æµå¼å“åº”å¯¼è‡´ JSON è§£æå¤±è´¥",
        "expected_topics": ["SSE", "stream", "false", "grok2api", "JSON"],
        "category": "Bug ä¿®å¤",
    },
    {
        "id": 5,
        "query": "Telegram é‡Œæ¶ˆæ¯åªèƒ½çœ‹åˆ°æœ€åä¸€æ®µ",
        "expected_topics": ["streamMode", "off", "partial", "Telegram"],
        "category": "é…ç½®ç»éªŒ",
    },
    {
        "id": 6,
        "query": "Python import ç¼ºå¤±è¢« try except åæ‰æ€ä¹ˆæ’æŸ¥",
        "expected_topics": ["import", "try", "except", "é™é»˜å¤±è´¥", "éšå¼ä¾èµ–"],
        "category": "è°ƒè¯•ç»éªŒ",
    },
    {
        "id": 7,
        "query": "æ€ä¹ˆæŠŠæ–‡ä»¶å­˜å…¥ OpenViking çŸ¥è¯†åº“",
        "expected_topics": ["add_resource", "target", "curated", "wait", "URI"],
        "category": "ä½¿ç”¨æŒ‡å—",
    },
    {
        "id": 8,
        "query": "curator å•æ–‡ä»¶é‡æ„ä¸ºæ¨¡å—åŒ…çš„ç»éªŒ",
        "expected_topics": ["æ¨¡å—åŒ–", "config", "router", "pipeline", "é‡æ„"],
        "category": "æ¶æ„ç»éªŒ",
    },
    {
        "id": 9,
        "query": "æ€ä¹ˆåšäº¤å‰éªŒè¯é˜²æ­¢å›ç­”ä¸å‡†ç¡®",
        "expected_topics": ["äº¤å‰éªŒè¯", "cross_validate", "å¤–æœ", "å…¥åº“", "å†²çª"],
        "category": "ç­–ç•¥ç»éªŒ",
    },
    {
        "id": 10,
        "query": "URI æ–°é²œåº¦å’Œä¿¡ä»»åº¦æ€ä¹ˆæ‰“åˆ†",
        "expected_topics": ["freshness", "trust", "æ—¶é—´è¡°å‡", "feedback", "score"],
        "category": "ç®—æ³•å®ç°",
    },
]


def run_raw_ov(query: str, limit: int = 5) -> dict:
    """è£¸ OpenViking æ£€ç´¢ï¼ˆHTTP APIï¼Œä¸ç»è¿‡ Curatorï¼‰ã€‚è¿”å› L2 contentã€‚"""
    import urllib.request

    def _post(path: str, payload: dict):
        req = urllib.request.Request(
            f"http://127.0.0.1:9100{path}",
            data=json.dumps(payload).encode(),
            headers={"Content-Type": "application/json"},
        )
        with urllib.request.urlopen(req, timeout=60) as resp:
            return json.loads(resp.read())

    def _get(path: str):
        with urllib.request.urlopen(f"http://127.0.0.1:9100{path}", timeout=60) as resp:
            return json.loads(resp.read())

    start = time.time()
    results = []
    seen = set()

    for path in ["/api/v1/search/search", "/api/v1/search/find"]:
        try:
            res = _post(path, {"query": query, "limit": limit}).get("result", {})
            for x in (res.get("resources", []) or []):
                u = x.get("uri", "")
                if u and u not in seen:
                    seen.add(u)
                    try:
                        import urllib.parse
                        enc = urllib.parse.quote(u, safe='/:')
                        content = (_get(f"/api/v1/content/read?uri={enc}").get("result", "") or "")[:1000]
                    except Exception:
                        content = x.get("abstract", "") or ""
                    results.append({"uri": u, "content": content})
        except Exception:
            pass

    elapsed = time.time() - start
    return {"results": results[:limit], "elapsed": round(elapsed, 2)}


def run_curator(query: str) -> dict:
    """Curator v2 å…¨æµç¨‹ã€‚è¿”å› context_textï¼ˆæ£€ç´¢å†…å®¹ï¼Œé LLM å›ç­”ï¼‰ã€‚"""
    import signal

    class TimeoutError(Exception):
        pass

    def _handler(signum, frame):
        raise TimeoutError("curator timeout")

    start = time.time()
    try:
        old_handler = signal.signal(signal.SIGALRM, _handler)
        signal.alarm(120)
        from curator.pipeline_v2 import run
        result = run(query)
        signal.alarm(0)
        signal.signal(signal.SIGALRM, old_handler)
        elapsed = time.time() - start
        return {
            "context_text": result.get("context_text", ""),
            "external_text": result.get("external_text", ""),
            "coverage": result.get("coverage", 0),
            "routed": True,
            "elapsed": round(elapsed, 2),
        }
    except Exception as e:
        signal.alarm(0)
        elapsed = time.time() - start
        return {"context_text": "", "error": str(e), "elapsed": round(elapsed, 2)}


def score_hit(content: str, expected_topics: list) -> dict:
    """è®¡ç®—æœŸæœ›å…³é”®è¯çš„å‘½ä¸­ç‡"""
    content_lower = content.lower()
    hits = []
    misses = []
    for topic in expected_topics:
        if topic.lower() in content_lower:
            hits.append(topic)
        else:
            misses.append(topic)
    return {
        "hit_rate": len(hits) / max(1, len(expected_topics)),
        "hits": hits,
        "misses": misses,
    }


def run_benchmark():
    """è¿è¡Œå®Œæ•´ benchmark"""
    results = []

    for q in BENCHMARK_QUERIES:
        print(f"\n{'='*60}")
        print(f"[{q['id']}/10] {q['category']}: {q['query']}")
        print(f"{'='*60}")

        # 1. è£¸ OVï¼šç”¨ L2 content
        raw = run_raw_ov(q["query"])
        raw_content = "\n".join(r["content"] for r in raw["results"])
        raw_score = score_hit(raw_content, q["expected_topics"])

        # 2. Curator v2ï¼šç”¨ context_textï¼ˆæ£€ç´¢å†…å®¹ï¼Œä¸æ˜¯ LLM ç”Ÿæˆçš„ answerï¼‰
        cur = run_curator(q["query"])
        cur_content = cur.get("context_text", "") + " " + cur.get("external_text", "")
        cur_score = score_hit(cur_content, q["expected_topics"])

        entry = {
            "id": q["id"],
            "query": q["query"],
            "category": q["category"],
            "raw_ov": {
                "hit_rate": raw_score["hit_rate"],
                "hits": raw_score["hits"],
                "misses": raw_score["misses"],
                "n_results": len(raw["results"]),
                "elapsed": raw["elapsed"],
            },
            "curator": {
                "hit_rate": cur_score["hit_rate"],
                "hits": cur_score["hits"],
                "misses": cur_score["misses"],
                "routed": cur.get("routed", False),
                "coverage": cur.get("coverage", 0),
                "elapsed": cur.get("elapsed", 0),
                "error": cur.get("error", ""),
            },
            "winner": "curator" if cur_score["hit_rate"] > raw_score["hit_rate"]
                      else "raw" if raw_score["hit_rate"] > cur_score["hit_rate"]
                      else "tie",
        }
        results.append(entry)

        # å®æ—¶è¾“å‡º
        print(f"  è£¸ OV:    å‘½ä¸­ {raw_score['hit_rate']:.0%} ({len(raw_score['hits'])}/{len(q['expected_topics'])})  {raw['elapsed']:.1f}s")
        print(f"  Curator:  å‘½ä¸­ {cur_score['hit_rate']:.0%} ({len(cur_score['hits'])}/{len(q['expected_topics'])})  {cur.get('elapsed', 0):.1f}s")
        print(f"  èƒœè€…: {entry['winner']}")

    # â”€â”€ æ±‡æ€» â”€â”€
    print(f"\n{'='*60}")
    print("ğŸ“Š æ±‡æ€»")
    print(f"{'='*60}")

    raw_avg = sum(r["raw_ov"]["hit_rate"] for r in results) / len(results)
    cur_avg = sum(r["curator"]["hit_rate"] for r in results) / len(results)
    raw_time = sum(r["raw_ov"]["elapsed"] for r in results) / len(results)
    cur_time = sum(r["curator"]["elapsed"] for r in results) / len(results)

    wins = {"curator": 0, "raw": 0, "tie": 0}
    for r in results:
        wins[r["winner"]] += 1

    print(f"  è£¸ OV å¹³å‡å‘½ä¸­ç‡:   {raw_avg:.0%}  å¹³å‡è€—æ—¶: {raw_time:.1f}s")
    print(f"  Curator å¹³å‡å‘½ä¸­ç‡: {cur_avg:.0%}  å¹³å‡è€—æ—¶: {cur_time:.1f}s")
    print(f"  æå‡: {(cur_avg - raw_avg) / max(0.01, raw_avg) * 100:+.0f}%")
    print(f"  èƒœè´Ÿ: Curator {wins['curator']} / è£¸OV {wins['raw']} / å¹³ {wins['tie']}")

    # â”€â”€ ä¿å­˜ç»“æœ â”€â”€
    out_dir = Path("/home/ponsde/OpenViking_Curator/eval/results")
    out_dir.mkdir(parents=True, exist_ok=True)
    out_file = out_dir / f"benchmark_{datetime.now().strftime('%Y-%m-%d_%H%M')}.json"

    summary = {
        "timestamp": datetime.now().isoformat(),
        "n_queries": len(results),
        "raw_avg_hit_rate": round(raw_avg, 3),
        "curator_avg_hit_rate": round(cur_avg, 3),
        "improvement_pct": round((cur_avg - raw_avg) / max(0.01, raw_avg) * 100, 1),
        "wins": wins,
        "raw_avg_time": round(raw_time, 2),
        "curator_avg_time": round(cur_time, 2),
        "details": results,
    }
    out_file.write_text(json.dumps(summary, ensure_ascii=False, indent=2))
    print(f"\nğŸ“ ç»“æœå·²ä¿å­˜: {out_file}")

    return summary


if __name__ == "__main__":
    run_benchmark()
